{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the dataset having 1969 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUCH better than the West Hollywood property w...</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stay away from room service in my opinion....</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Room service was superb.</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stayed in a king suite for 11 nights and yes i...</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The location close to the 72nd Street subway s...</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    cat\n",
       "0  MUCH better than the West Hollywood property w...  Hotel\n",
       "1      Stay away from room service in my opinion....  Hotel\n",
       "2                           Room service was superb.  Hotel\n",
       "3  Stayed in a king suite for 11 nights and yes i...  Hotel\n",
       "4  The location close to the 72nd Street subway s...  Hotel"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = pd.read_csv('dataset/review-dump.csv')\n",
    "dset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the vectorizer on Reviews Dataset (1969 reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tfidf(dset):\n",
    "    porter = nltk.PorterStemmer()\n",
    "    doc = []\n",
    "    dset['review'] = dset['review'].astype('str')\n",
    "    for x in dset['review']:\n",
    "        x = x.decode('utf-8')\n",
    "        x.encode('ascii', 'ignore')\n",
    "        tokens = word_tokenize(x)\n",
    "        stem = [porter.stem(t) for t in tokens]\n",
    "        doc.append(' '.join(stem))\n",
    "    # print doc\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "    vectorizer.fit(doc)\n",
    "    print len(vectorizer.vocabulary_)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This returns the most similar video with the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_from_similarity(df, vectorizer, sent, vdo_dict, watchlist):\n",
    "    porter = nltk.PorterStemmer()\n",
    "    tk = word_tokenize(sent)\n",
    "    stem = [porter.stem(t) for t in tk]\n",
    "    vec2 = vectorizer.transform([' '.join(stem)])\n",
    "    cosim, euclid, i1, i2 = 0.0, float('inf'), -1, -1\n",
    "    s1, s2 = \"\", \"\"\n",
    "    for x in range(0, len(df['video_name'])):\n",
    "        token = word_tokenize(df['video_name'][x])\n",
    "        words = [w.lower() for w in token]\n",
    "        stem_token = [porter.stem(t) for t in words]\n",
    "        vec = vectorizer.transform([' '.join(stem_token)])\n",
    "        tmp = cosine_similarity(vec, vec2)\n",
    "        if tmp > cosim:\n",
    "            cosim = tmp\n",
    "            s1 = df['video_name'][x]\n",
    "            i1 = df['id'][x]\n",
    "        tmp2 = euclidean_distances(vec, vec2)\n",
    "        if tmp2 < euclid:\n",
    "            euclid = tmp2\n",
    "            s2 = df['video_name'][x]\n",
    "            i2 = df['id'][x]\n",
    "\n",
    "    vdo_dict[i1] = [sent, s1, df['video_url'][df['id']==i1].values]\n",
    "    vdo_dict[i2] = [sent, s2, df['video_url'][df['id']==i2].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/video_details.csv')\n",
    "vdo_df = pd.read_csv('dataset/video.csv')\n",
    "review = pd.read_csv('dataset/review.csv')\n",
    "watchlist = pd.read_csv('dataset/watchlist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_watch_limit = 45\n",
    "till_date = (datetime.date.today() - datetime.timedelta(video_watch_limit)).isoformat()\n",
    "watchlist = watchlist[((watchlist['is_watched']==1) & (watchlist['updated_at']<=till_date) | (watchlist['is_watched']==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['id'].isin(watchlist['video_details_id_id'].values)]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38325\n"
     ]
    }
   ],
   "source": [
    "vectorizer = train_tfidf(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo_dict = {}\n",
    "sentiment = -0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dic is  8 \n",
      "\n",
      "128  ->  ['The quality of hotel is bad', 'CLEARANCE OF PLATES', array(['http://d255tx56tiemkm.cloudfront.net/Cafe+Videos/Cafe+Service/CLEARANCE+OF+PLATES.mp4'],\n",
      "      dtype=object)] \n",
      "\n",
      "138  ->  ['The room was not according to expectation', 'Preparing to clean the room process', array(['http://d255tx56tiemkm.cloudfront.net/GRA+Videos/Room+Cleaning/Preparing+To+Clean+The+Room/Hk-preparing+To+Clean+The+Room+5march.m4v'],\n",
      "      dtype=object)] \n",
      "\n",
      "87  ->  ['Extra bedsheets were not there', 'Extra Bed Placement Process', array(['http://d255tx56tiemkm.cloudfront.net/GRA+Articulate+Made+Videos/Extra+Bed+Placement/Extra+Bed+Placement+09.03.18.mp4'],\n",
      "      dtype=object)] \n",
      "\n",
      "12  ->  ['there was smell coming from bathroom', 'Bathroom Cleaning-Replenishing Supplies & Mopping', array(['http://d255tx56tiemkm.cloudfront.net/GRA+Videos/Bathroom+Cleaning/Replenishing+Supplies+%26+Mopping/Hk-replenishing+Supplies+%26+Mopping%5B1%5D+5march-1.m4v'],\n",
      "      dtype=object)] \n",
      "\n",
      "45  ->  ['AC was not working', 'AC filter cleaning- Process & frequency', array(['http://d255tx56tiemkm.cloudfront.net/GRA+Videos/AC+Filter+Cleaning/ac+cleaning%5B1-1%5D+5+march.mp4'],\n",
      "      dtype=object)] \n",
      "\n",
      "25  ->  ['there was smell coming from bathroom', 'Divermite chemicals', array(['http://d255tx56tiemkm.cloudfront.net/GRA+Videos/Caddy+Setup/OYO+Divermite+5march.mp4'],\n",
      "      dtype=object)] \n",
      "\n",
      "89  ->  ['The room service is bad', 'Servicing guest room (Occupied room)', array(['http://d255tx56tiemkm.cloudfront.net/GRA+Articulate+Made+Videos/Servicing+Occupied+Guest+Room/Servicing+guest+room+(occupied)+08.03.18.mp4'],\n",
      "      dtype=object)] \n",
      "\n",
      "187  ->  ['minibar was not in the room', 'MOT - Check In Shown In A Dirty Room', array(['http://d255tx56tiemkm.cloudfront.net/GRE+Videos/MOT-Check+In+Shown+In+A+Dirty+Room.mp4'],\n",
      "      dtype=object)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(0, 7):\n",
    "    if sentiment <= 0.0:\n",
    "        get_video_from_similarity(df, vectorizer, review['review'][x], vdo_dict, watchlist)\n",
    "\n",
    "print \"Length of dic is \", len(vdo_dict), '\\n'\n",
    "for k,v in vdo_dict.items():\n",
    "    print k, \" -> \", v, '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on Cause Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n",
      "set([35, 36, 37, 38])\n"
     ]
    }
   ],
   "source": [
    "tag = pd.read_csv('dataset/tags.csv')\n",
    "cause = pd.read_csv('dataset/cause.csv')\n",
    "solver = pd.read_csv('dataset/solver.csv')\n",
    "\n",
    "tag_id = tag['id'][tag.subject.isin(['Appliances']) & tag.attribute.isin(['Availability']) & tag.domain.isin(['Room Making']) & tag.department.isin(['Housekeeping'])].values\n",
    "print tag_id\n",
    "\n",
    "cause_id = set(solver['cause_id_id'][solver['tag_id_id'].isin(tag_id)].values)\n",
    "print (cause_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['This item is not a part of a offering'], dtype=object), array(['This item was Out Of Order'], dtype=object), array(['This item was being used by another guest'], dtype=object), array(['Staff not aware that this item is a part of the offering'],\n",
      "      dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "cause_doc = []\n",
    "# cause_doc.append(cause['causetext'][cause.id.isin(cause_id)].values)\n",
    "for x in cause_id:\n",
    "    cause_doc.append(cause['causetext'].values[cause.id==(x)])\n",
    "    \n",
    "print cause_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staff was untrained ->  -1.0\n",
      "Did not receive linen on time from the vendor -> Linen Exchange & Discard Process (Handing over soiled linen & Receiving fresh linen) 8\n",
      "Fresh linen not available -> Linen Exchange & Discard Process (Handing over soiled linen & Receiving fresh linen) 8\n",
      "Did not receive the right quantity of linen back from the vendor -> Linen Exchange & Discard Process (Handing over soiled linen & Receiving fresh linen) 8\n",
      "Room not checked by GRE/HM -> MOT - Check Out 70\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "for cs in cause_doc:\n",
    "    token = word_tokenize(cs[0])\n",
    "    stem = [porter.stem(t) for t in token]\n",
    "    vec2 = vectorizer.transform([' '.join(stem)])\n",
    "    cosim, i1 = 0.0, -1.0\n",
    "    s1 = \"\"\n",
    "    for x in range(0, len(df['video_name'])):\n",
    "        tok = word_tokenize(df['video_name'][x])\n",
    "        stem_token = [porter.stem(t) for t in tok]\n",
    "        vec = vectorizer.transform([' '.join(stem_token)])\n",
    "        tmp = cosine_similarity(vec, vec2)\n",
    "        if tmp > cosim:\n",
    "            cosim = tmp\n",
    "            s1 = df['video_name'][x]\n",
    "            i1 = df['id'][x]\n",
    "    \n",
    "    print cs[0], \"->\", s1, i1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now training on GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    f = open(gloveFile, 'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print \"Trained Model\", len(model), \" words loaded!\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Model 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "model = loadGloveModel('dataset/glove/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51518   0.80125  -0.13731  -0.472     1.0321   -0.75538  -0.58585\n",
      " -0.10406  -0.22021  -0.38029  -0.82568  -0.1288   -0.059862  0.8529\n",
      "  0.54697   0.43243  -0.54769   0.35936  -0.14251  -1.2086    0.72885\n",
      "  1.0991   -0.34049   0.014483 -0.20405  -0.98005  -0.07667   1.0827\n",
      "  0.34461  -0.37714   2.8916    0.23911  -0.091089 -0.45495   0.24013\n",
      "  0.92777   0.77564   0.37424   0.84257  -0.34445   0.049718  0.27486\n",
      " -0.35371   1.0032    0.081324  0.25981   0.17708  -1.1572   -0.080012\n",
      "  0.08214 ]\n"
     ]
    }
   ],
   "source": [
    "print model['room']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "with open('dataset/stopwords.txt') as f:\n",
    "    content = f.readlines()\n",
    "stop_words = [x.strip() for x in content]\n",
    "print len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_feature_vector(sentence, num_features=50):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    if(n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9922950354472008\n"
     ]
    }
   ],
   "source": [
    "s1 = avg_feature_vector('this is a sentence')\n",
    "s2 = avg_feature_vector('this is also a sentence')\n",
    "\n",
    "from scipy import spatial\n",
    "sim = 1 - spatial.distance.cosine(s1, s2)\n",
    "print sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_from_glovesimilarity(df, sent, vdo):\n",
    "    vec2 = avg_feature_vector(sent)\n",
    "    cosim, i1 = 0.0, -1\n",
    "    s1, s2 = \"\", \"\"\n",
    "    for x in range(0, len(df['video_name'])):\n",
    "        vec = avg_feature_vector(df['video_name'][x])\n",
    "        tmp = 1 - spatial.distance.cosine(vec, vec2)\n",
    "        if tmp > cosim:\n",
    "            cosim = tmp\n",
    "            s1 = df['video_name'][x]\n",
    "            i1 = df['id'][x]\n",
    "    print i1, sent, tmp\n",
    "    vdo[i1] = [sent, s1, df['video_url'][df['id']==i1].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 The room service is bad 0.6477380624640072\n",
      "86 The quality of hotel is bad 0.6605280783037595\n",
      "91 The room was not according to expectation 0.6077790295183275\n",
      "86 minibar was not in the room 0.6489408303757652\n",
      "91 AC was not working 0.5981857433961429\n",
      "91 Extra bedsheets were not there 0.5157426543209019\n",
      "86 there was smell coming from bathroom 0.583887136575734\n",
      "Length of dic is  2 \n",
      "\n",
      "91  ->  ['Extra bedsheets were not there', 'Pest Control (Records to be maintained)', array(['http://d255tx56tiemkm.cloudfront.net/GRA+Articulate+Made+Videos/Pest+Control/Pest+Control+2+09.03.18.mp4'],\n",
      "      dtype=object)] \n",
      "\n",
      "86  ->  ['there was smell coming from bathroom', 'Occupied room set up (Things to do in an occupied room & bathroom)', array(['http://d255tx56tiemkm.cloudfront.net/GRA+Articulate+Made+Videos/Difference+In+Services/Difference+in+services-occupied+room+setup+09.03.18.mp4'],\n",
      "      dtype=object)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vdo = {}\n",
    "for x in range(0, 7):\n",
    "    if sentiment <= 0.0:\n",
    "        get_video_from_glovesimilarity(df, review['review'][x], vdo)\n",
    "\n",
    "print \"Length of dic is \", len(vdo), '\\n'\n",
    "for k,v in vdo.items():\n",
    "    print k, \" -> \", v, '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo2 = {}\n",
    "for x in range(0, 7):\n",
    "    if sentiment <= 0.0:\n",
    "        sent = review['review'][x].split()\n",
    "        resultwords  = [word for word in sent if word.lower() not in stop_words]\n",
    "        result = ' '.join(resultwords)\n",
    "        get_video_from_glovesimilarity(df, result, vdo2, watchlist)\n",
    "\n",
    "print \"Length of dic is \", len(vdo2), '\\n'\n",
    "for k,v in vdo2.items():\n",
    "    print k, \" -> \", v, '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staff was untrained\n",
      "['Pest Control (Records to be maintained)']\n",
      "['Occupied room set up (Things to do in an occupied room & bathroom)']\n",
      "['Check out call process (When it should be performed & objective of this process)']\n",
      "\n",
      "\n",
      "Did not receive linen on time from the vendor\n",
      "['Occupied room set up (Things to do in an occupied room & bathroom)']\n",
      "['Vacant room set up (Things to do in a vacant room & bathroom)']\n",
      "['Starting the day (starting the day, check grooming, points to remember, GRA uniform)']\n",
      "\n",
      "\n",
      "Fresh linen not available\n",
      "['Vacant room set up (Things to do in a vacant room & bathroom)']\n",
      "['Check out call process (When it should be performed & objective of this process)']\n",
      "['Pest Control (Records to be maintained)']\n",
      "\n",
      "\n",
      "Did not receive the right quantity of linen back from the vendor\n",
      "['Starting the day (starting the day, check grooming, points to remember, GRA uniform)']\n",
      "['Occupied room set up (Things to do in an occupied room & bathroom)']\n",
      "['Pest Control (Records to be maintained)']\n",
      "\n",
      "\n",
      "Room not checked by GRE/HM\n",
      "['Pest Control (Records to be maintained)']\n",
      "['Check out call process (When it should be performed & objective of this process)']\n",
      "['Starting the day (starting the day, check grooming, points to remember, GRA uniform)']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cs in cause_doc:\n",
    "    li = []\n",
    "    vec2 = avg_feature_vector(cs[0])\n",
    "    for x in range(0, len(df['video_name'])):\n",
    "        vec = avg_feature_vector(df['video_name'][x])\n",
    "        tmp = 1 - spatial.distance.cosine(vec, vec2)\n",
    "        if(math.isnan(tmp)):\n",
    "            continue\n",
    "        i1 = df['id'][x]\n",
    "        li.append((tmp,i1))\n",
    "    li = sorted(li, reverse=True)\n",
    "    li = li[:3]\n",
    "    print cs[0]\n",
    "    for f,s in li:\n",
    "        print df['video_name'][df['id']==s].values\n",
    "    print '\\n'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Glove embedding on sentence after removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staff was untrained -> Staff untrained\n",
      "['Pest Control (Rodent management, cockroach management, ant management, fly management & mosquito man']\n",
      "['soliciting feedback Cafe']\n",
      "['Bathtub cleaning- Bathtub & corners scrubbing']\n",
      "\n",
      "\n",
      "Did not receive linen on time from the vendor -> not receive linen time vendor\n",
      "['Reception Area cleaning (Paintings, switch plate & coffee table cleaning)']\n",
      "['order taking repeating & closing an order']\n",
      "['Preparing to clean the room process']\n",
      "\n",
      "\n",
      "Fresh linen not available -> Fresh linen not available\n",
      "['Reception Area cleaning (Paintings, switch plate & coffee table cleaning)']\n",
      "['Preparing to clean the room process']\n",
      "['Room Layout & Amenities (Writing table contents & amenities basket)']\n",
      "\n",
      "\n",
      "Did not receive the right quantity of linen back from the vendor -> not receive right quantity linen back vendor\n",
      "['order taking repeating & closing an order']\n",
      "['Reception Area cleaning (Paintings, switch plate & coffee table cleaning)']\n",
      "['Preparing to clean the room process']\n",
      "\n",
      "\n",
      "Room not checked by GRE/HM -> Room not checked GRE/HM\n",
      "['Check out call process (Missing & breakage report filling process)']\n",
      "['order taking repeating & closing an order']\n",
      "['Starting the day (starting the day, check grooming, points to remember, GRA uniform)']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cs in cause_doc:\n",
    "    li = []\n",
    "    words = cs[0].split()\n",
    "    resultwords  = [word for word in words if word.lower() not in stop_words]\n",
    "    result = ' '.join(resultwords)\n",
    "#     print cs[0]\n",
    "#     print result\n",
    "    vec2 = avg_feature_vector(result)\n",
    "    for x in range(0, len(df['video_name'])):\n",
    "        reswords = [word for word in df['video_name'][x].split() if word.lower() not in stop_words]\n",
    "        res = ' '.join(reswords)\n",
    "        vec = avg_feature_vector(res)\n",
    "        tmp = 1 - spatial.distance.cosine(vec, vec2)\n",
    "        if(math.isnan(tmp)):\n",
    "            continue\n",
    "        i1 = df['id'][x]\n",
    "        li.append((tmp,i1))\n",
    "    li = sorted(li, reverse=True)\n",
    "    li = li[:3]\n",
    "    print cs[0], \"->\", result\n",
    "    for f,s in li:\n",
    "        print df['video_name'][df['id']==s].values\n",
    "    print '\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
